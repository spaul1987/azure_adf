{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "testing-adf-nonprod-dev02"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/DS_input_Excel')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "Tabelle1",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "test_exist.xlsx",
						"container": "azureadf"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "Emp ID",
						"type": "String"
					},
					{
						"name": "Role",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText2",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText2",
								"type": "DatasetReference"
							},
							"name": "source2"
						},
						{
							"dataset": {
								"referenceName": "DS_input_Excel",
								"type": "DatasetReference"
							},
							"name": "Sourceexist"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText3",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Aggregate1"
						},
						{
							"name": "Join1"
						},
						{
							"name": "Exists1"
						}
					],
					"script": "source(output(\n\t\t{Emp Name} as string,\n\t\t{Emp ID} as string,\n\t\tRole as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tlimit: 100,\n\tignoreNoFilesFound: false) ~> source1\nsource(output(\n\t\t{Emp Name} as string,\n\t\t{Emp ID} as string,\n\t\tRole as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tlimit: 100,\n\tignoreNoFilesFound: false) ~> source2\nsource(output(\n\t\t{Emp ID} as string,\n\t\tRole as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tlimit: 100,\n\tignoreNoFilesFound: false) ~> Sourceexist\nsource1 aggregate(groupBy({Emp Name}),\n\tCount = count()) ~> Aggregate1\nAggregate1, source2 join(Aggregate1@{Emp Name} == source2@{Emp Name},\n\tjoinType:'inner',\n\tbroadcast: 'auto')~> Join1\nJoin1, Sourceexist exists(source2@{Emp ID} == Sourceexist@{Emp ID}\n\t&& source2@Role == Sourceexist@Role,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists1\nExists1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['Test_Check.csv'],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tpartitionBy('hash', 1)) ~> sink1"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_input_Excel')]"
			]
		}
	]
}